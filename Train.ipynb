{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":5430,"status":"ok","timestamp":1725113535133,"user":{"displayName":"Ali","userId":"06474794958265016440"},"user_tz":-210},"id":"-s3cvFAIpVwg"},"outputs":[],"source":["import gc\n","import numpy as np\n","import os\n","import shutil\n","import cv2\n","import matplotlib.pyplot as plt\n","import datetime\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision.transforms as T\n","import torchvision.transforms.functional as TF\n","import sys\n","\n","from torch.utils.data import Dataset,DataLoader\n","from torchvision import transforms\n","from torch import optim , Tensor\n","from tqdm import tqdm\n","from os import listdir\n","from os.path import isfile, join\n","from pathlib import Path\n","from copy import deepcopy\n","from PIL import Image\n","\n","from Utils import *\n","from Loss_Functions import *\n","from Aug import *\n","from U_Net import *\n"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1725114584076,"user":{"displayName":"Ali","userId":"06474794958265016440"},"user_tz":-210},"id":"x30CYrt7OVaK"},"outputs":[],"source":["def train_model(\n","        input_ch,\n","        model,\n","        device,\n","        augmentation,\n","        use_aug_data,\n","        epochs,\n","        T_max,\n","        train_batch_size,\n","        val_batch_size,\n","        test_batch_size,\n","        learning_rate,\n","        eta_min,\n","        momentum,\n","        weight_decay,\n","        size,\n","        alpha_Focal,\n","        gamma_Focal,\n","        alpha_FocalTversky,\n","        gamma_FocalTversky,\n","        alpha_WBCE,\n","        reduction,\n","        use_loss1,\n","        use_loss2,\n","        use_loss3,\n","        use_loss4,\n","        use_loss5,\n","        use_loss6,\n","        first_norm,\n","        optimizer_type,\n","        scheduler_type,\n","        time_str):\n","\n","    calculate_loss = criterion(alpha_Focal,gamma_Focal,alpha_FocalTversky,gamma_FocalTversky,alpha_WBCE,reduction,\n","                               use_loss1,use_loss2,use_loss3,use_loss4,use_loss5,use_loss6)\n","\n","    #------------------------------------------------------------------------------------------------\n","\n","    if optimizer_type == 'Adam':\n","        optimizer = optim.Adam(model.parameters(),lr=learning_rate, weight_decay=weight_decay)\n","    if optimizer_type == 'AdamW':\n","        optimizer = optim.AdamW(model.parameters(),lr=learning_rate, weight_decay=weight_decay)\n","    if optimizer_type == 'SGD':\n","        optimizer = optim.SGD(model.parameters(), lr=learning_rate, weight_decay=weight_decay, momentum=momentum)\n","\n","    if scheduler_type == 'Reduce':\n","      scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2, cooldown=1)\n","    if scheduler_type == 'Cosine':\n","      scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max, eta_min=eta_min)\n","\n","    #------------------------------------------------------------------------------------------------\n","    num_params_text = 'num params:' + str(get_num_params(model)) + '\\n'\n","    print(num_params_text)\n","    dir = f'/content/drive/MyDrive/DENTISTRY/MODELS/{time_str}'\n","    os.makedirs(dir,exist_ok=True)\n","\n","    #----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n","\n","    min_val_loss = float('inf')\n","    max_val_iou = 0\n","\n","    for epoch in range(1, epochs + 1):\n","\n","        epoch_text = 'epoch:' + str(epoch)\n","        lr_text = 'lr:' + str(optimizer.state_dict()['param_groups'][0]['lr'])\n","        print(epoch_text)\n","        print(lr_text)\n","\n","        #------------------------------------------------------------------------------------------------\n","\n","        train_loss = 0\n","        train_iou = 0\n","        train_dice = 0\n","        train_sens = 0\n","        train_spec = 0\n","        train_precision = 0\n","        train_F1 = 0\n","        num_train_samples = 0\n","\n","        model.train()\n","        enable_grad(model)\n","\n","        if use_aug_data:\n","            train_dataset = dataset(images_path = aug_train_images_path, masks_path = aug_train_masks_path, input_ch = input_ch, size=size, normalize=not first_norm)\n","        else:\n","            train_dataset = dataset(images_path = train_images_path, masks_path = train_masks_path, input_ch = input_ch, size=size, normalize=not first_norm)\n","        train_data = DataLoader(dataset=train_dataset,batch_size=train_batch_size,shuffle=True)\n","\n","        for batch in tqdm(train_data):\n","\n","            images, masks = batch['images'], batch['masks']\n","            if augmentation == True:\n","                images, masks = augment(images, masks, input_ch = input_ch, size = size)\n","            images = images.to(device=device)\n","            masks = masks.to(device=device)\n","            num_train_samples = num_train_samples + len(images)\n","\n","            optimizer.zero_grad()\n","            pred = model(images)\n","\n","            loss = calculate_loss(pred, masks)\n","            train_loss += loss*len(images)\n","\n","            pred_thres = (pred>=0.5).float()\n","            iou, dice, sens, spec, precision, F1 = calculate_metrics(pred_thres, masks)\n","            train_iou += iou\n","            train_dice += dice\n","            train_sens += sens\n","            train_spec += spec\n","            train_precision += precision\n","            train_F1 += F1\n","\n","            loss.backward()\n","            optimizer.step()\n","\n","        train_iou = train_iou.item()/num_train_samples\n","        train_dice = train_dice.item()/num_train_samples\n","        train_sens = train_sens.item()/num_train_samples\n","        train_spec = train_spec.item()/num_train_samples\n","        train_precision = train_precision.item()/num_train_samples\n","        train_F1 = train_F1.item()/num_train_samples\n","\n","        #------------------------------------------------------------------------------------------------\n","\n","        val_loss = 0\n","        val_iou = 0\n","        val_dice = 0\n","        val_sens = 0\n","        val_spec = 0\n","        val_precision = 0\n","        val_F1 = 0\n","        num_val_samples = 0\n","\n","        disable_grad(model)\n","\n","        val_dataset = dataset(images_path = val_images_path, masks_path = val_masks_path, input_ch = input_ch, size=size, normalize=not first_norm)\n","        val_data = DataLoader(dataset=val_dataset,batch_size=val_batch_size,shuffle=False)\n","\n","        with torch.no_grad():\n","            for batch in tqdm(val_data):\n","\n","                images, masks = batch['images'], batch['masks']\n","                images = images.to(device=device)\n","                masks = masks.to(device=device)\n","\n","                num_val_samples = num_val_samples + len(images)\n","                pred = model(images)\n","                loss = calculate_loss(pred, masks)\n","                val_loss += loss*len(images)\n","\n","                pred_thres = (pred>=0.5).float()\n","                iou, dice, sens, spec, precision, F1 = calculate_metrics(pred_thres, masks)\n","                val_iou += iou\n","                val_dice += dice\n","                val_sens += sens\n","                val_spec += spec\n","                val_precision += precision\n","                val_F1 += F1\n","\n","            val_iou = val_iou.item()/num_val_samples\n","            val_dice = val_dice.item()/num_val_samples\n","            val_sens = val_sens.item()/num_val_samples\n","            val_spec = val_spec.item()/num_val_samples\n","            val_precision = val_precision.item()/num_val_samples\n","            val_F1 = val_F1.item()/num_val_samples\n","\n","        if scheduler_type == 'Reduce':\n","          scheduler.step(val_iou)\n","        if scheduler_type == 'Cosine':\n","          scheduler.step()\n","        #------------------------------------------------------------------------------------------------\n","\n","        train_loss = train_loss.item()/num_train_samples\n","        val_loss = val_loss.item()/num_val_samples\n","\n","        if val_loss < min_val_loss:\n","            min_val_loss = val_loss\n","            max_val_iou = val_iou\n","            model_params = model.state_dict()\n","            torch.save(model_params,dir+'/best_model.pth')\n","\n","        print('\\n')\n","        print('Train Set')\n","        print(f'Loss: {train_loss:0.6f} - iou: {train_iou:0.6f} - dice: {train_dice:0.6f} - sens: {train_sens:0.6f} - precision: {train_precision:0.6f} - F1: {train_F1:0.6f}')\n","\n","        print('Val Set')\n","        print(f'Loss: {val_loss:0.6f} - iou: {val_iou:0.6f} - dice: {val_dice:0.6f} - sens: {val_sens:0.6f} - precision: {val_precision:0.6f} - F1: {val_F1:0.6f} - best loss: {min_val_loss:0.6f} - best iou: {max_val_iou:0.6f}')\n","        print('------------------------------------------------------------------------------------------------------------------')\n","\n","    #----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n","\n","    model_params = model.state_dict()\n","    torch.save(model_params,dir+'/final_model.pth')\n","\n","    #----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n","\n","    test_dataset = dataset(images_path = test_images_path, masks_path = test_masks_path, input_ch = input_ch, size=size, normalize=not first_norm)\n","    test_data = DataLoader(dataset=test_dataset,batch_size=test_batch_size,shuffle=False)\n","\n","    test_loss = 0\n","    test_iou = 0\n","    test_dice = 0\n","    test_sens = 0\n","    test_spec = 0\n","    test_precision = 0\n","    test_F1 = 0\n","    num_test_samples = 0\n","\n","    model.load_state_dict(torch.load(dir+'/best_model.pth'))\n","    disable_grad(model)\n","\n","    with torch.no_grad():\n","        for batch in tqdm(test_data):\n","\n","            images, masks = batch['images'], batch['masks']\n","            images = images.to(device=device)\n","            masks = masks.to(device=device)\n","\n","            num_test_samples = num_test_samples + len(images)\n","            pred = model(images)\n","            loss = calculate_loss(pred, masks)\n","            test_loss += loss*len(images)\n","\n","            pred_thres = (pred>=0.5).float()\n","            iou, dice, sens, spec, precision, F1 = calculate_metrics(pred_thres, masks)\n","            test_iou += iou\n","            test_dice += dice\n","            test_sens += sens\n","            test_spec += spec\n","            test_precision += precision\n","            test_F1 += F1\n","\n","        test_iou = test_iou.item()/num_test_samples\n","        test_dice = test_dice.item()/num_test_samples\n","        test_sens = test_sens.item()/num_test_samples\n","        test_spec = test_spec.item()/num_test_samples\n","        test_precision = test_precision.item()/num_test_samples\n","        test_F1 = test_F1.item()/num_test_samples\n","        test_loss = test_loss.item()/num_test_samples\n","\n","        print('\\n')\n","        print('Test Set')\n","        print(f'Loss: {test_loss:0.6f} - iou: {test_iou:0.6f} - dice: {test_dice:0.6f} - sens: {test_sens:0.6f} - precision: {test_precision:0.6f} - F1: {test_F1:0.6f}')\n","        print('------------------------------------------------------------------------------------------------------------------')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":588097,"status":"ok","timestamp":1720906996902,"user":{"displayName":"Ali","userId":"06474794958265016440"},"user_tz":-210},"id":"BIIVjdyeOVaM","outputId":"37d2a270-a80b-4416-e772-56c92e41e54d"},"outputs":[],"source":["dataset_name = 'NEW_DATASET_3'\n","\n","aug_train_images_path = f\"/content/{dataset_name}/AUG-TRAIN-IMAGES\"\n","aug_train_masks_path = f\"/content/{dataset_name}/AUG-TRAIN-MASKS\"\n","\n","train_images_path = f\"/content/{dataset_name}/TRAIN-IMAGES\"\n","train_masks_path = f\"/content/{dataset_name}/TRAIN-MASKS\"\n","\n","val_images_path = f\"/content/{dataset_name}/VAL-IMAGES\"\n","val_labels_path = f\"/content/{dataset_name}/VAL-LABELS\"\n","val_masks_path = f\"/content/{dataset_name}/VAL-MASKS\"\n","\n","test_images_path = f\"/content/{dataset_name}/TEST-IMAGES\"\n","test_labels_path = f\"/content/{dataset_name}/TEST-LABELS\"\n","test_masks_path = f\"/content/{dataset_name}/TEST-MASKS\"\n","\n","#----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n","\n","current_time = datetime.datetime.now()\n","Year = current_time.year\n","Month = current_time.month\n","Day = current_time.day\n","Hour = current_time.hour\n","Minute = current_time.minute\n","Second = current_time.second\n","\n","time_str = f'{Year}-{Month:02}-{Day:02} -- {Hour:02}-{Minute:02}-{Second:02}'\n","print(time_str)\n","\n","#----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n","\n","input_ch = 1\n","dropout = 0.1\n","size = (256,256)\n","batch_size = 20\n","\n","alpha_Focal = 3\n","gamma_Focal = 1\n","alpha_WBCE = 1\n","alpha_FocalTversky = 0.3\n","gamma_FocalTversky = 1\n","reduction = 'mean'\n","\n","use_loss1= bool(1)\n","use_loss2= bool(0)\n","use_loss3= bool(0)\n","use_loss4= bool(1)\n","use_loss5= bool(0)\n","use_loss6= bool(0)\n","\n","augmentation = bool(1)\n","use_aug_data = bool(0)\n","\n","optimizer_type='SGD'\n","scheduler_type='Reduce'\n","\n","first_norm = bool(1)\n","torch.cuda.empty_cache()\n","\n","#----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n","\n","d = 32\n","device = torch.device('cuda')\n","model = UNet(in_channels=input_ch,d1=d,d2=2*d,d3=4*d,d4=8*d,d5=16*d,kernel1=3,padding1=1,kernel2=3,padding2=1,device=device,dtype = torch.float32, dropout=dropout, first_norm=False)\n","\n","model.to(device)\n","#model.load_state_dict(torch.load('/content/drive/MyDrive/DENTISTRY/MODELS/2024-07-06 -- 22-35-03/best_model.pth'))\n","#----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n","\n","train_model(\n","    input_ch = input_ch,\n","    model = model,\n","    device = device,\n","    augmentation = augmentation,\n","    use_aug_data = use_aug_data,\n","    time_str = time_str,\n","    train_batch_size = batch_size,\n","    val_batch_size = batch_size,\n","    test_batch_size = batch_size,\n","    size=size,\n","    alpha_Focal = alpha_Focal,\n","    gamma_Focal = gamma_Focal,\n","    alpha_FocalTversky = alpha_FocalTversky,\n","    gamma_FocalTversky = gamma_FocalTversky,\n","    alpha_WBCE = alpha_WBCE,\n","    reduction = reduction,\n","    use_loss1 = use_loss1,\n","    use_loss2 = use_loss2,\n","    use_loss3 = use_loss3,\n","    use_loss4 = use_loss4,\n","    use_loss5 = use_loss5,\n","    use_loss6 = use_loss6,\n","    first_norm = first_norm,\n","    optimizer_type = optimizer_type,\n","    scheduler_type = scheduler_type,\n","    epochs = 50,\n","    learning_rate = 1e-1,\n","    eta_min = 1e-5,\n","    momentum = 0.9,\n","    weight_decay = 1e-4,\n","    T_max = 100)\n"]},{"cell_type":"markdown","metadata":{"id":"vMR6WvyfgSCt"},"source":["---"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1235,"status":"ok","timestamp":1725116612522,"user":{"displayName":"Ali","userId":"06474794958265016440"},"user_tz":-210},"id":"qwzlBuYMUY2E","outputId":"6d666602-d5e1-4593-a391-d08f9fadecc8"},"outputs":[],"source":["dataset_name = 'NEW_DATASET_3'\n","\n","aug_train_images_path = f\"/content/{dataset_name}/AUG-TRAIN-IMAGES\"\n","aug_train_masks_path = f\"/content/{dataset_name}/AUG-TRAIN-MASKS\"\n","\n","train_images_path = f\"/content/{dataset_name}/TRAIN-IMAGES\"\n","train_masks_path = f\"/content/{dataset_name}/TRAIN-MASKS\"\n","\n","val_images_path = f\"/content/{dataset_name}/VAL-IMAGES\"\n","val_labels_path = f\"/content/{dataset_name}/VAL-LABELS\"\n","val_masks_path = f\"/content/{dataset_name}/VAL-MASKS\"\n","\n","test_images_path = f\"/content/{dataset_name}/TEST-IMAGES\"\n","test_labels_path = f\"/content/{dataset_name}/TEST-LABELS\"\n","test_masks_path = f\"/content/{dataset_name}/TEST-MASKS\"\n","\n","#----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n","\n","input_ch = 1\n","dropout = 0.1\n","size = (256,256)\n","batch_size = 20\n","\n","alpha_Focal = 3\n","gamma_Focal = 1\n","alpha_WBCE = 1\n","alpha_FocalTversky = 0.3\n","gamma_FocalTversky = 1\n","reduction = 'mean'\n","\n","use_loss1= bool(1)\n","use_loss2= bool(0)\n","use_loss3= bool(0)\n","use_loss4= bool(1)\n","use_loss5= bool(0)\n","use_loss6= bool(0)\n","\n","augmentation = bool(1)\n","use_aug_data = bool(0)\n","\n","optimizer_type='SGD'\n","scheduler_type='Reduce'\n","\n","first_norm = bool(1)\n","torch.cuda.empty_cache()\n","\n","#----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n","\n","d = 32\n","device = torch.device('cuda')\n","model = UNet(in_channels=input_ch,d1=d,d2=2*d,d3=4*d,d4=8*d,d5=16*d,kernel1=3,padding1=1,kernel2=3,padding2=1,device=device,dtype = torch.float32, dropout=dropout, first_norm=False)\n","\n","model.to(device)\n","model.load_state_dict(torch.load('/content/drive/MyDrive/DENTISTRY/MODELS/2024-07-13 -- 21-33-29/best_model.pth'))\n","\n","#d = 32\n","#device = torch.device('cuda')\n","#model = UNet(in_channels=input_ch,d1=d,d2=2*d,d3=4*d,d4=8*d,d5=16*d,kernel1=3,padding1=1,kernel2=3,padding2=1,device=device,dtype = torch.float32, dropout=dropout, first_norm=True)\n","#model.to(device)\n","\n","#dir = f'/content/drive/MyDrive/DENTISTRY/MODELS/{time_str}'\n","#model.load_state_dict(torch.load(dir+'/final_model.pth'))\n","#model.load_state_dict(torch.load(dir+'/best_model.pth'))\n","\n","#--------------------------------------------------------------------------------------------------------------------------------------------\n","\n","train_dataset = dataset(images_path = train_images_path, masks_path = train_masks_path, input_ch = input_ch, size=size, normalize=not first_norm)\n","val_dataset = dataset(images_path = val_images_path, masks_path = val_masks_path, input_ch = input_ch, size=size, normalize=not first_norm)\n","test_dataset = dataset(images_path = test_images_path, masks_path = test_masks_path, input_ch = input_ch, size=size, normalize=not first_norm)\n","\n","train_data = DataLoader(dataset=train_dataset,batch_size=5,shuffle=False)\n","val_data = DataLoader(dataset=val_dataset,batch_size=5,shuffle=False)\n","test_data = DataLoader(dataset=test_dataset,batch_size=5,shuffle=False)\n","\n","#--------------------------------------------------------------------------------------------------------------------------------------------\n","\n","calculate_loss = criterion(alpha_Focal,gamma_Focal,alpha_FocalTversky,gamma_FocalTversky,alpha_WBCE,reduction,use_loss1,use_loss2,use_loss3,use_loss4,use_loss5,use_loss6)\n","\n","#--------------------------------------------------------------------------------------------------------------------------------------------\n","\n","total_loss = 0\n","total_iou = 0\n","total_dice = 0\n","total_sens = 0\n","total_spec = 0\n","total_precision = 0\n","total_F1 = 0\n","total_mae = 0\n","num_samples = 0\n","\n","#--------------------------------------------------------------------------------------------------------------------------------------------\n","\n","torch.cuda.manual_seed(0)\n","torch.manual_seed(0)\n","\n","i = 2\n","dataloader = [train_data,val_data,test_data]\n","name = ['train_data','val_data','test_data']\n","\n","#dataloader = [train_data,val_data]\n","#name = ['train_data','val_data']\n","\n","#--------------------------------------------------------------------------------------------------------------------------------------------\n","\n","disable_grad(model)\n","\n","with torch.no_grad():\n","  for batch in tqdm(dataloader[i]):\n","\n","      images, masks = batch['images'], batch['masks']\n","      images = images.to(device=device)\n","      masks = masks.to(device=device)\n","\n","      num_samples = num_samples + len(images)\n","      pred = model(images)\n","\n","      loss = calculate_loss(pred, masks)\n","      total_loss += loss*len(images)\n","\n","      pred_thres = (pred>=0.5).float()\n","      iou, dice, sens, spec, precision, F1, mae = calculate_metrics_for_test(pred_thres, masks)\n","      total_iou += iou\n","      total_dice += dice\n","      total_sens += sens\n","      total_spec += spec\n","      total_precision += precision\n","      total_F1 += F1\n","      total_mae += mae\n","\n","  total_iou = total_iou.item()/num_samples\n","  total_dice = total_dice.item()/num_samples\n","  total_sens = total_sens.item()/num_samples\n","  total_spec = total_spec.item()/num_samples\n","  total_precision = total_precision.item()/num_samples\n","  total_F1 = total_F1.item()/num_samples\n","  total_mae = total_mae.item()/num_samples\n","  total_loss = total_loss.item()/num_samples\n","\n","  print('\\n')\n","  print(f'{name[i]} - iou: {total_iou:0.6f} - dice: {total_dice:0.6f} - sens (recall): {total_sens:0.6f} - spec: {total_spec:0.6f} - precision: {total_precision:0.6f} - F1: {total_F1:0.6f} - mae: {total_mae:0.6f}')\n","  print('------------------------------------------------------------------------------------------------------------------')\n"]},{"cell_type":"markdown","metadata":{"id":"_AxTTuVsuheT"},"source":["---"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1MMyhrA0pVl7JNEuwnsjySfRSEjKQuVCa"},"executionInfo":{"elapsed":69824,"status":"ok","timestamp":1720907312388,"user":{"displayName":"Ali","userId":"06474794958265016440"},"user_tz":-210},"id":"Evgazh9pKYQY","outputId":"4bd3e3aa-0112-4269-f693-1299b5eef6b0"},"outputs":[],"source":["#torch.manual_seed(10)\n","#torch.cuda.manual_seed(10)\n","\n","#d = 32\n","#device = torch.device('cuda')\n","#model = UNet(in_channels=input_ch,d1=d,d2=2*d,d3=4*d,d4=8*d,d5=16*d,kernel1=3,padding1=1,kernel2=3,padding2=1,device=device,dtype = torch.float32, dropout=dropout, first_norm=first_norm)\n","#model.to(device)\n","\n","disable_grad(model)\n","dir = f'/content/drive/MyDrive/DENTISTRY/MODELS/{time_str}'\n","#model.load_state_dict(torch.load(dir+'/final_model.pth'))\n","#model.load_state_dict(torch.load(dir+'/best_model.pth'))\n","\n","#----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n","\n","new_dataset = special_dataset(images_path=test_images_path,masks_path=test_masks_path, labels_path=test_labels_path,size=size, normalize=not first_norm)\n","#new_dataset = special_dataset(images_path=val_images_path,masks_path=val_masks_path, labels_path=val_labels_path,size=size, normalize=not first_norm)\n","\n","for i in range(0,20):\n","\n","    data, img_name = new_dataset.__getitem__(i)\n","\n","    with torch.no_grad():\n","      disable_grad(model)\n","      output = model(data['images'].to(device).unsqueeze(0))\n","    output = output.squeeze(0,1)\n","\n","    # add threshold\n","    thresh = 0.5\n","    output_thresh = (output >= thresh).float().to('cpu').detach().numpy()\n","    output = output.to('cpu').detach().numpy()\n","    yellow_output = color(data['images_view'],output_thresh,1,1,0)\n","    red_output = data['labels']\n","    test = torch.concatenate((data['images_view'].squeeze(0).unsqueeze(2).repeat(1,1,3),red_output,yellow_output),dim=1)\n","\n","    plt.figure(i,figsize=(20,20))\n","    plt.figtext(0, 0.5, img_name, fontsize=15)\n","    plt.subplot(111), plt.imshow(test)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tOlTI7xKHh-Q"},"outputs":[],"source":["disable_grad(model)\n","dir = f'/content/drive/MyDrive/DENTISTRY/MODELS/{time_str}'\n","#model.load_state_dict(torch.load(dir+'/final_model.pth'))\n","#model.load_state_dict(torch.load(dir+'/best_model.pth'))\n","\n","new_dataset = special_dataset(images_path=test_images_path,masks_path=test_masks_path, labels_path=test_labels_path,size=size, normalize=not first_norm)\n","#new_dataset = special_dataset(images_path=val_images_path,masks_path=val_masks_path, labels_path=val_labels_path,size=size, normalize=not first_norm)\n","\n","for i in range(0,new_dataset.__len__()):\n","\n","    data, img_name = new_dataset.__getitem__(i)\n","\n","    with torch.no_grad():\n","      disable_grad(model)\n","      output = model(data['images'].to(device).unsqueeze(0))\n","    output = output.squeeze(0,1)\n","\n","    # add threshold\n","    thresh = 0.5\n","    output_thresh = (output >= thresh).float().to('cpu').detach().numpy()\n","    output = output.to('cpu').detach().numpy()\n","    yellow_output = color(data['images_view'],output_thresh,1,1,0)\n","    red_output = data['labels']\n","    test = torch.concatenate((data['images_view'].squeeze(0).unsqueeze(2).repeat(1,1,3),red_output,yellow_output),dim=1).numpy()*255\n","    test = cv2.cvtColor(test,cv2.COLOR_BGR2RGB)\n","\n","    output_folder = f\"output_{time_str}\"\n","    os.makedirs(output_folder,exist_ok=True)\n","    cv2.imwrite(output_folder + '/' + img_name, test)\n","\n","    source_file = output_folder + '/' + img_name\n","    destination_path = f'/content/drive/MyDrive/DENTISTRY/{output_folder}'\n","    os.makedirs(destination_path,exist_ok=True)\n","    shutil.copy(source_file, destination_path)\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"},"vscode":{"interpreter":{"hash":"e8755eff31258cf3f68aa399e6f759d79082959dfad6f58a9830d0e0b06355a5"}}},"nbformat":4,"nbformat_minor":0}
